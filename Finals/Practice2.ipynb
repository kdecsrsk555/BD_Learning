{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11a6d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#필요한 라이브러리 호출 공간\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46756088",
   "metadata": {},
   "source": [
    "데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553e616c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 불러오기\n",
    "file_name = \"\"\n",
    "def reading_csv(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    print(df.shape)\n",
    "    print(df.head())\n",
    "    return df\n",
    "\n",
    "df = reading_csv(file_name)\n",
    "\n",
    "# 결측치 확인\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# 결측치 처리 (평균 or 최빈값 or 중위값)\n",
    "si = SimpleImputer(strategy=\"mean\")\n",
    "ss = StandardScaler()\n",
    "le = LabelEncoder()\n",
    "oe = OneHotEncoder(sparse=False)\n",
    "num_col = []\n",
    "cat_col = []\n",
    " \n",
    "def processing(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # 수치형 컬럼 처리\n",
    "    df[num_col] = si.fit_transform(df[num_col])\n",
    "    df['파생변수'] = pd.cut(df['col'], bins=[0, 18, 30, 50, 100], labels=['Teen', 'Young', 'Adults', 'Senior'])\n",
    "    df[num_col] = ss.fit_transform(df[num_col])\n",
    "\n",
    "    # 범주형 컬럼 처리\n",
    "    for col in cat_col:# label encoding\n",
    "            df[col] = le.fit_transform(df[col])\n",
    "\n",
    "    return df\n",
    "\n",
    "processed_df = processing(df)\n",
    "print(processed_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523ee0ca",
   "metadata": {},
   "source": [
    "Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14852af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 타겟 변수 지정\n",
    "target_col = 'target'  # 실제 변수명으로 변경\n",
    "\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "# 훈련/검증 데이터 분할 (8:2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee432c46",
   "metadata": {},
   "source": [
    "모델 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01aa9909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 적용 및 성능 평가\n",
    "from sklearn import linear_model  \n",
    "# 로지스틱 회귀 (이진 분류에 특화)\n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "# 앙상블 모델: 여러 결정트리를 결합하여 성능 향상\n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "# 단순 신경망 기반의 선형 분류기\n",
    "from sklearn.linear_model import Perceptron  \n",
    "# 확률적 경사하강법 기반 선형 분류기\n",
    "from sklearn.linear_model import SGDClassifier  \n",
    "# 결정 트리 기반 분류기 (if-else 형태의 트리 구조)\n",
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "# K-최근접 이웃 알고리즘 (거리 기반 분류)\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "# 서포트 벡터 머신 (복잡한 경계 분류, 마진 기반)\n",
    "# LinearSVC: 선형 SVM (SVM의 일종, 대용량에 빠르고 선형 분리에 적합)\n",
    "from sklearn.svm import SVC, LinearSVC  \n",
    "# 확률 기반 분류기 (조건부 독립 가정)\n",
    "from sklearn.naive_bayes import GaussianNB  \n",
    "\n",
    "# 🔹 [3] 시각화 도구 임포트\n",
    "import seaborn as sns  \n",
    "%matplotlib inline  \n",
    "from matplotlib import pyplot as plt  \n",
    "from matplotlib import style  # 그래프 스타일 지정용\n",
    "\n",
    "# 의사결정 나무 --> 복자도가 높아지면 일반화 성능이 떨어짐, 과적합 가능성\n",
    "decision_tree=DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, y_train)\n",
    "Y_pred=decision_tree.predict(X_test)\n",
    "train_acc_decision_tree=round(decision_tree.score(X_train, y_train)*100, 2)\n",
    "test_acc_decision_tree=round(decision_tree.score(X_test, y_test)*100, 2)\n",
    "train_acc_decision_tree,test_acc_decision_tree\n",
    "\n",
    "\n",
    "# 랜덤 포레스트 --> 과적합 방지에 강함, 하지만 하이퍼파라미터 기본값 사용 등으로 일반화 성능이 크게 향상되지 않음\n",
    "# max_depth, min_sample_leaf 제한\n",
    "# n_estimator 증가\n",
    "# GridSearchCV 사용 --> 최적의 하이퍼 파라미터 조건 탐색\n",
    "random_forest=RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(X_train, y_train)\n",
    "Y_prediction=random_forest.predict(X_test)\n",
    "random_forest.score(X_train, y_train)\n",
    "train_acc_random_forest=round(random_forest.score(X_train, y_train)*100, 2)\n",
    "test_acc_random_forest=round(random_forest.score(X_test, y_test)*100, 2)\n",
    "train_acc_random_forest,test_acc_random_forest\n",
    "\n",
    "\n",
    "# 로지스틱 회귀 --> 과적합 위험 낮음, 특히 특성이 별로 없을 때\n",
    "log_reg=LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "Y_pred=log_reg.predict(X_test)\n",
    "train_acc_log=round(log_reg.score(X_train, y_train)*100, 2)\n",
    "test_acc_log=round(log_reg.score(X_test, y_test)*100, 2)\n",
    "train_acc_log, test_acc_log\n",
    "\n",
    "\n",
    "# 나이브 베이즈 --> 로지스틱 회귀보다 성능 낮음\n",
    "gaussian=GaussianNB()\n",
    "gaussian.fit(X_train, y_train)\n",
    "Y_pred=gaussian.predict(X_test)\n",
    "train_acc_gaussian=round(gaussian.score(X_train, y_train)*100, 2)\n",
    "test_acc_gaussian=round(gaussian.score(X_test, y_test)*100, 2)\n",
    "train_acc_gaussian,test_acc_gaussian\n",
    "\n",
    "# Linear SVC\n",
    "svc=LinearSVC()\n",
    "svc.fit(X_train, y_train)\n",
    "Y_pred=svc.predict(X_test)\n",
    "train_acc_svc=round(svc.score(X_train, y_train)*100, 2)\n",
    "test_acc_svc=round(svc.score(X_test, y_test)*100, 2)\n",
    "train_acc_svc,test_acc_svc\n",
    "\n",
    "# Perceptron\n",
    "perceptron=Perceptron(max_iter=5)\n",
    "perceptron.fit(X_train, y_train)\n",
    "Y_pred=perceptron.predict(X_test)\n",
    "train_acc_perceptron=round(perceptron.score(X_train, y_train)*100, 2)\n",
    "test_acc_perceptron=round(perceptron.score(X_test, y_test)*100, 2)\n",
    "train_acc_perceptron,test_acc_perceptron\n",
    "\n",
    "\n",
    "#SDGclassifier --> 과소적합 (max_iter 늘려야됨)\n",
    "sgd=linear_model.SGDClassifier(max_iter=5, tol=None)\n",
    "sgd.fit(X_train, y_train)\n",
    "Y_pred=sgd.predict(X_test)\n",
    "sgd.score(X_train, y_train)\n",
    "train_acc_sgd=round(sgd.score(X_train, y_train)*100, 2)\n",
    "test_acc_sgd=round(sgd.score(X_test, y_test)*100, 2)\n",
    "train_acc_sgd,test_acc_sgd\n",
    "\n",
    "\n",
    "#모델 비교 방식\n",
    "results = pd.DataFrame({\n",
    " 'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', 'Random Forest','Naive Bayes', 'Perceptron', 'Stochastic Gradient Decent', 'Decision Tree'],\n",
    " 'train_Score': [train_acc_svc, train_acc_knn, train_acc_log,train_acc_random_forest,\n",
    "train_acc_gaussian, train_acc_perceptron, train_acc_sgd, train_acc_decision_tree],\n",
    " 'test_Score': [test_acc_svc, test_acc_knn,test_acc_log, test_acc_random_forest, test_acc_gaussian, test_acc_perceptron, test_acc_sgd, test_acc_decision_tree]})\n",
    "result_df=results.sort_values(by='train_Score', ascending=False)\n",
    "result_df=result_df.set_index('Model')\n",
    "result_df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0528e25",
   "metadata": {},
   "source": [
    "5. 정리\n",
    "\n",
    "\"모든 모델은 도구일 뿐, 문제에 맞게 골라 써야 한다.\"\n",
    "\n",
    "직관이 필요한가? → 결정나무\n",
    "\n",
    "정확도가 중요한가? → 랜덤 포레스트\n",
    "\n",
    "실시간 데이터인가? → SGD\n",
    "\n",
    "적은 데이터인가? → 나이브 베이즈\n",
    "\n",
    "변수 간 복잡한 관계가 있는가? → SVM or 앙상블\n",
    "\n",
    "\n",
    "\n",
    "항목 & 고려 내용\n",
    "\n",
    "데이터 크기 --> 작다면 SVM/로지스틱, 크면 SGD/랜덤포레스트\n",
    "\n",
    "변수 간 관계 --> 독립성 높다면 나이브 베이즈 적합\n",
    "\n",
    "정형/비정형 데이터 --> 정형이면 대부분 모델 사용 가능, 비정형이면 딥러닝 계열\n",
    "\n",
    "실행 시간 --> 실시간 처리 필요하면 SGDClassifier\n",
    "\n",
    "결과 해석 필요 --> 의사결정나무, 로지스틱 회귀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0389ff23",
   "metadata": {},
   "source": [
    "변수 중요도 및 하이퍼파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18320f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# 기존 모델 학습\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 변수 중요도 시각화 및 상위 3개 변수 추출\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# 변수 중요도 상위 3개\n",
    "top_3_features = [X_train.columns[i] for i in indices[:3]]\n",
    "print(\"Top 3 중요 변수:\", top_3_features)\n",
    "\n",
    "# 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.bar(range(X_train.shape[1]), importances[indices], align=\"center\")\n",
    "plt.xticks(range(X_train.shape[1]), X_train.columns[indices], rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bf40df",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=42),\n",
    "                           param_grid, scoring='f1', cv=3, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Params:\", grid_search.best_params_)\n",
    "\n",
    "# 튜닝된 모델로 예측\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_before = model.predict(X_test)\n",
    "y_pred_after = best_model.predict(X_test)\n",
    "\n",
    "print(\"Before tuning - Accuracy:\", accuracy_score(y_test, y_pred_before))\n",
    "print(\"Before tuning - F1 Score:\", f1_score(y_test, y_pred_before, average='macro'))\n",
    "\n",
    "print(\"After tuning - Accuracy:\", accuracy_score(y_test, y_pred_after))\n",
    "print(\"After tuning - F1 Score:\", f1_score(y_test, y_pred_after, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30e5752",
   "metadata": {},
   "source": [
    "오버피팅 점검 및 해결방안"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ae3a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터와 검증 데이터 성능 비교\n",
    "train_acc = best_model.score(X_train, y_train)\n",
    "test_acc = best_model.score(X_test, y_test)\n",
    "\n",
    "print(\"Train Accuracy:\", train_acc)\n",
    "print(\"Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d44720",
   "metadata": {},
   "source": [
    "성능 차이가 클 경우 → 과적합(overfitting) 가능성 있음.\n",
    "\n",
    "오버피팅 방지 방법 제안\n",
    "교차 검증 (Cross-validation)\n",
    "\n",
    "정규화 (Regularization)\n",
    "\n",
    "변수 개수 축소 / 불필요한 변수 제거\n",
    "\n",
    "모델 복잡도 제한 (max_depth, min_samples_split 조정 등)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf6c8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max depth 제한을 통해 모델 복잡도 제한\n",
    "simple_model = RandomForestClassifier(max_depth=5, random_state=42)\n",
    "simple_model.fit(X_train, y_train)\n",
    "y_simple_pred = simple_model.predict(X_test)\n",
    "\n",
    "print(\"After applying max_depth=5 - Accuracy:\", accuracy_score(y_test, y_simple_pred))\n",
    "print(\"After applying max_depth=5 - F1 Score:\", f1_score(y_test, y_simple_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e088b499",
   "metadata": {},
   "source": [
    "종합 해석 및 제안\n",
    "\n",
    "### 모델 활용 방안\n",
    "해당 분류 모델은 예측 정확도가 높고 변수 중요도를 해석할 수 있어, 예측이 필요한 실제 업무에 적용 가능하다. 예: 고객 이탈 예측, 질병 분류, 이상 거래 탐지 등\n",
    "\n",
    "### 성능 향상을 위한 데이터 측면 제안\n",
    "1. **더 많은 학습 데이터 확보**: 현재 데이터가 제한적일 경우, 추가 수집을 통해 일반화 성능 향상 가능\n",
    "2. **도메인 특화된 파생변수 생성**: 단순 변수 외에도 업무 지식에 기반한 파생 변수 추가 시 성능 향상 가능\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
