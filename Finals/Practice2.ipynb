{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11a6d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜¸ì¶œ ê³µê°„\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46756088",
   "metadata": {},
   "source": [
    "ë°ì´í„° ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553e616c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "file_name = \"\"\n",
    "def reading_csv(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    print(df.shape)\n",
    "    print(df.head())\n",
    "    return df\n",
    "\n",
    "df = reading_csv(file_name)\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ í™•ì¸\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (í‰ê·  or ìµœë¹ˆê°’ or ì¤‘ìœ„ê°’)\n",
    "si = SimpleImputer(strategy=\"mean\")\n",
    "ss = StandardScaler()\n",
    "le = LabelEncoder()\n",
    "oe = OneHotEncoder(sparse=False)\n",
    "num_col = []\n",
    "cat_col = []\n",
    "\n",
    "def processing(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ì²˜ë¦¬\n",
    "    df[num_col] = si.fit_transform(df[num_col])\n",
    "    df['íŒŒìƒë³€ìˆ˜'] = pd.cut(df['col'], bins=[0, 18, 30, 50, 100], labels=['Teen', 'Young', 'Adults', 'Senior'])\n",
    "    df[num_col] = ss.fit_transform(df[num_col])\n",
    "\n",
    "    # ë²”ì£¼í˜• ì»¬ëŸ¼ ì²˜ë¦¬\n",
    "    for col in cat_col:# label encoding\n",
    "            df[col] = le.fit_transform(df[col])\n",
    "\n",
    "    return df\n",
    "\n",
    "processed_df = processing(df)\n",
    "print(processed_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523ee0ca",
   "metadata": {},
   "source": [
    "Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14852af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# íƒ€ê²Ÿ ë³€ìˆ˜ ì§€ì •\n",
    "target_col = 'target'  # ì‹¤ì œ ë³€ìˆ˜ëª…ìœ¼ë¡œ ë³€ê²½\n",
    "\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "# í›ˆë ¨/ê²€ì¦ ë°ì´í„° ë¶„í•  (8:2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee432c46",
   "metadata": {},
   "source": [
    "ëª¨ë¸ ì ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01aa9909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ì ìš© ë° ì„±ëŠ¥ í‰ê°€\n",
    "from sklearn import linear_model  \n",
    "# ë¡œì§€ìŠ¤í‹± íšŒê·€ (ì´ì§„ ë¶„ë¥˜ì— íŠ¹í™”)\n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "# ì•™ìƒë¸” ëª¨ë¸: ì—¬ëŸ¬ ê²°ì •íŠ¸ë¦¬ë¥¼ ê²°í•©í•˜ì—¬ ì„±ëŠ¥ í–¥ìƒ\n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "# ë‹¨ìˆœ ì‹ ê²½ë§ ê¸°ë°˜ì˜ ì„ í˜• ë¶„ë¥˜ê¸°\n",
    "from sklearn.linear_model import Perceptron  \n",
    "# í™•ë¥ ì  ê²½ì‚¬í•˜ê°•ë²• ê¸°ë°˜ ì„ í˜• ë¶„ë¥˜ê¸°\n",
    "from sklearn.linear_model import SGDClassifier  \n",
    "# ê²°ì • íŠ¸ë¦¬ ê¸°ë°˜ ë¶„ë¥˜ê¸° (if-else í˜•íƒœì˜ íŠ¸ë¦¬ êµ¬ì¡°)\n",
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "# K-ìµœê·¼ì ‘ ì´ì›ƒ ì•Œê³ ë¦¬ì¦˜ (ê±°ë¦¬ ê¸°ë°˜ ë¶„ë¥˜)\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "# ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹  (ë³µì¡í•œ ê²½ê³„ ë¶„ë¥˜, ë§ˆì§„ ê¸°ë°˜)\n",
    "# LinearSVC: ì„ í˜• SVM (SVMì˜ ì¼ì¢…, ëŒ€ìš©ëŸ‰ì— ë¹ ë¥´ê³  ì„ í˜• ë¶„ë¦¬ì— ì í•©)\n",
    "from sklearn.svm import SVC, LinearSVC  \n",
    "# í™•ë¥  ê¸°ë°˜ ë¶„ë¥˜ê¸° (ì¡°ê±´ë¶€ ë…ë¦½ ê°€ì •)\n",
    "from sklearn.naive_bayes import GaussianNB  \n",
    "\n",
    "# ğŸ”¹ [3] ì‹œê°í™” ë„êµ¬ ì„í¬íŠ¸\n",
    "import seaborn as sns  \n",
    "%matplotlib inline  \n",
    "from matplotlib import pyplot as plt  \n",
    "from matplotlib import style  # ê·¸ë˜í”„ ìŠ¤íƒ€ì¼ ì§€ì •ìš©\n",
    "\n",
    "# ì˜ì‚¬ê²°ì • ë‚˜ë¬´ --> ë³µìë„ê°€ ë†’ì•„ì§€ë©´ ì¼ë°˜í™” ì„±ëŠ¥ì´ ë–¨ì–´ì§, ê³¼ì í•© ê°€ëŠ¥ì„±\n",
    "decision_tree=DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, y_train)\n",
    "Y_pred=decision_tree.predict(X_test)\n",
    "train_acc_decision_tree=round(decision_tree.score(X_train, y_train)*100, 2)\n",
    "test_acc_decision_tree=round(decision_tree.score(X_test, y_test)*100, 2)\n",
    "train_acc_decision_tree,test_acc_decision_tree\n",
    "\n",
    "\n",
    "# ëœë¤ í¬ë ˆìŠ¤íŠ¸ --> ê³¼ì í•© ë°©ì§€ì— ê°•í•¨, í•˜ì§€ë§Œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê¸°ë³¸ê°’ ì‚¬ìš© ë“±ìœ¼ë¡œ ì¼ë°˜í™” ì„±ëŠ¥ì´ í¬ê²Œ í–¥ìƒë˜ì§€ ì•ŠìŒ\n",
    "# max_depth, min_sample_leaf ì œí•œ\n",
    "# n_estimator ì¦ê°€\n",
    "# GridSearchCV ì‚¬ìš© --> ìµœì ì˜ í•˜ì´í¼ íŒŒë¼ë¯¸í„° ì¡°ê±´ íƒìƒ‰\n",
    "random_forest=RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(X_train, y_train)\n",
    "Y_prediction=random_forest.predict(X_test)\n",
    "random_forest.score(X_train, y_train)\n",
    "train_acc_random_forest=round(random_forest.score(X_train, y_train)*100, 2)\n",
    "test_acc_random_forest=round(random_forest.score(X_test, y_test)*100, 2)\n",
    "train_acc_random_forest,test_acc_random_forest\n",
    "\n",
    "\n",
    "# ë¡œì§€ìŠ¤í‹± íšŒê·€ --> ê³¼ì í•© ìœ„í—˜ ë‚®ìŒ, íŠ¹íˆ íŠ¹ì„±ì´ ë³„ë¡œ ì—†ì„ ë•Œ\n",
    "log_reg=LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "Y_pred=log_reg.predict(X_test)\n",
    "train_acc_log=round(log_reg.score(X_train, y_train)*100, 2)\n",
    "test_acc_log=round(log_reg.score(X_test, y_test)*100, 2)\n",
    "train_acc_log, test_acc_log\n",
    "\n",
    "\n",
    "# ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ --> ë¡œì§€ìŠ¤í‹± íšŒê·€ë³´ë‹¤ ì„±ëŠ¥ ë‚®ìŒ\n",
    "gaussian=GaussianNB()\n",
    "gaussian.fit(X_train, y_train)\n",
    "Y_pred=gaussian.predict(X_test)\n",
    "train_acc_gaussian=round(gaussian.score(X_train, y_train)*100, 2)\n",
    "test_acc_gaussian=round(gaussian.score(X_test, y_test)*100, 2)\n",
    "train_acc_gaussian,test_acc_gaussian\n",
    "\n",
    "# Linear SVC\n",
    "svc=LinearSVC()\n",
    "svc.fit(X_train, y_train)\n",
    "Y_pred=svc.predict(X_test)\n",
    "train_acc_svc=round(svc.score(X_train, y_train)*100, 2)\n",
    "test_acc_svc=round(svc.score(X_test, y_test)*100, 2)\n",
    "train_acc_svc,test_acc_svc\n",
    "\n",
    "# Perceptron\n",
    "perceptron=Perceptron(max_iter=5)\n",
    "perceptron.fit(X_train, y_train)\n",
    "Y_pred=perceptron.predict(X_test)\n",
    "train_acc_perceptron=round(perceptron.score(X_train, y_train)*100, 2)\n",
    "test_acc_perceptron=round(perceptron.score(X_test, y_test)*100, 2)\n",
    "train_acc_perceptron,test_acc_perceptron\n",
    "\n",
    "\n",
    "#SDGclassifier --> ê³¼ì†Œì í•© (max_iter ëŠ˜ë ¤ì•¼ë¨)\n",
    "sgd=linear_model.SGDClassifier(max_iter=5, tol=None)\n",
    "sgd.fit(X_train, y_train)\n",
    "Y_pred=sgd.predict(X_test)\n",
    "sgd.score(X_train, y_train)\n",
    "train_acc_sgd=round(sgd.score(X_train, y_train)*100, 2)\n",
    "test_acc_sgd=round(sgd.score(X_test, y_test)*100, 2)\n",
    "train_acc_sgd,test_acc_sgd\n",
    "\n",
    "\n",
    "#ëª¨ë¸ ë¹„êµ ë°©ì‹\n",
    "results = pd.DataFrame({\n",
    " 'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', 'Random Forest','Naive Bayes', 'Perceptron', 'Stochastic Gradient Decent', 'Decision Tree'],\n",
    " 'train_Score': [train_acc_svc, train_acc_knn, train_acc_log,train_acc_random_forest,\n",
    "train_acc_gaussian, train_acc_perceptron, train_acc_sgd, train_acc_decision_tree],\n",
    " 'test_Score': [test_acc_svc, test_acc_knn,test_acc_log, test_acc_random_forest, test_acc_gaussian, test_acc_perceptron, test_acc_sgd, test_acc_decision_tree]})\n",
    "result_df=results.sort_values(by='train_Score', ascending=False)\n",
    "result_df=result_df.set_index('Model')\n",
    "result_df.head(10)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
