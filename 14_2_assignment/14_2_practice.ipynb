{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37f2768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ… í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from transformers import BertTokenizerFast, BertForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "import torch\n",
    "\n",
    "# âœ… 1. IMDB ì˜í™” ë¦¬ë·° ë°ì´í„°ì…‹ ë¡œë“œ\n",
    "# IMDBëŠ” 'train'ê³¼ 'test'ë¡œ ë‚˜ë‰œ binary classificationìš© ê°ì„± ë°ì´í„°ì…‹\n",
    "dataset = load_dataset(\"imdb\")\n",
    "\n",
    "# âœ… 2. ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•œ ê· í˜•ì¡íŒ ìƒ˜í”Œë§\n",
    "# ì•„ë˜ ë°©ì‹ìœ¼ë¡œ ë°ì´í„° í›ˆë ¨/í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ì„ íƒ í•  ê²½ìš° ë°ì´í„° í¸í–¥ìœ¼ë¡œ ì¸í•œ ê³¼ì í•© ë˜ëŠ” ì˜¤ì í•© ë°œìƒ\n",
    "# train_data = dataset[\"train\"].select(range(2000))  # ë©”ëª¨ë¦¬ ì´ˆê³¼ ë°©ì§€ìš©\n",
    "# test_data = dataset[\"test\"].select(range(500))     # ë©”ëª¨ë¦¬ ì´ˆê³¼ ë°©ì§€ìš©\n",
    "# ì›ë³¸ train ë°ì´í„°ëŠ” ë¶€ì •(0) ë¦¬ë·°ê°€ ì•ìª½ì— ëª°ë ¤ ìˆìŒ â‡’ ëª¨ë¸ í¸í–¥ ìœ ë°œ\n",
    "# ë”°ë¼ì„œ ë¶€ì •/ê¸ì • ê°ê° 5000ê°œì”© ë¬´ì‘ìœ„ ì¶”ì¶œí•˜ì—¬ ê· í˜• ìœ ì§€\n",
    "neg_samples = dataset[\"train\"].filter(lambda x: x['label'] == 0).shuffle(seed=42).select(range(5000))\n",
    "pos_samples = dataset[\"train\"].filter(lambda x: x['label'] == 1).shuffle(seed=42).select(range(5000))\n",
    "\n",
    "# ë¶€ì •/ê¸ì • ê²°í•© í›„ ë‹¤ì‹œ ì…”í”Œí•˜ì—¬ train ë°ì´í„° êµ¬ì„±\n",
    "balanced_dataset = concatenate_datasets([neg_samples, pos_samples]).shuffle(seed=42)\n",
    "\n",
    "# âœ… 3. í•™ìŠµ/í‰ê°€ìš© ë°ì´í„° ë¶„ë¦¬\n",
    "# í•™ìŠµ ë°ì´í„°: ê· í˜• ìƒ˜í”Œ ì¤‘ 2,000ê°œ ì‚¬ìš© (Colab í™˜ê²½ ê³ ë ¤)\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„°: ì›ë³¸ IMDB test ë°ì´í„° ì¤‘ 500ê°œ ì‚¬ìš©\n",
    "train_data = balanced_dataset.select(range(2000))\n",
    "test_data = load_dataset(\"imdb\")[\"test\"].select(range(500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23eb097e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'label'],\n",
      "    num_rows: 500\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09434b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11314"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ë°ì´í„° ë¡œë”©\n",
    "newsgroups_train = fetch_20newsgroups(subset='train', remove=('headers', 'footers', 'quotes'))\n",
    "newsgroups_test = fetch_20newsgroups(subset='test', remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "len(newsgroups_train.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61b66eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alt.atheism\n",
      "comp.graphics\n",
      "comp.os.ms-windows.misc\n",
      "comp.sys.ibm.pc.hardware\n",
      "comp.sys.mac.hardware\n",
      "comp.windows.x\n",
      "misc.forsale\n",
      "rec.autos\n",
      "rec.motorcycles\n",
      "rec.sport.baseball\n",
      "rec.sport.hockey\n",
      "sci.crypt\n",
      "sci.electronics\n",
      "sci.med\n",
      "sci.space\n",
      "soc.religion.christian\n",
      "talk.politics.guns\n",
      "talk.politics.mideast\n",
      "talk.politics.misc\n",
      "talk.religion.misc\n"
     ]
    }
   ],
   "source": [
    "for a in newsgroups_test.target_names:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2cabda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# âœ‚ï¸ í›ˆë ¨ ë°ì´í„°ì…‹ì—ì„œ ë¦¬ë·° í…ìŠ¤íŠ¸ì™€ ë¼ë²¨ë§Œ ë¶„ë¦¬í•˜ì—¬ ë³„ë„ ë³€ìˆ˜ì— ì €ì¥\n",
    "train_texts = train_data[\"text\"]   # ë¦¬ë·° ë³¸ë¬¸ í…ìŠ¤íŠ¸ ëª©ë¡ (ë¦¬ìŠ¤íŠ¸ í˜•íƒœ)\n",
    "train_labels = train_data[\"label\"] # ê°ì„± ë ˆì´ë¸” (0: ë¶€ì •, 1: ê¸ì •)\n",
    "\n",
    "# ğŸ”¤ ì‚¬ì „í•™ìŠµëœ BERTìš© í† í¬ë‚˜ì´ì € ë¡œë“œ (WordPiece ê¸°ë°˜ í† í°í™”)\n",
    "# 'bert-base-uncased'ëŠ” ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ì†Œë¬¸ìë¡œ ì²˜ë¦¬í•¨\n",
    "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# âœ‚ï¸ ìµœëŒ€ ì‹œí€€ìŠ¤ ê¸¸ì´ ì„¤ì • (ë„ˆë¬´ ê¸´ ë¬¸ì¥ì€ ìë¥´ê³ , ì§§ì€ ë¬¸ì¥ì€ íŒ¨ë”©í•¨)\n",
    "MAX_LEN = 256\n",
    "\n",
    "# ğŸ§ª í† í¬ë‚˜ì´ì €ë¡œ ë¬¸ì¥ë“¤ì„ BERT ì…ë ¥ í˜•íƒœë¡œ ë³€í™˜\n",
    "# truncation=True â†’ ê¸¸ë©´ ìë¥´ê¸° / padding='max_length' â†’ ì§§ìœ¼ë©´ 256ê¸¸ì´ì— ë§ì¶° íŒ¨ë”©\n",
    "# return_tensors=\"pt\" â†’ PyTorch í…ì„œ í˜•íƒœë¡œ ë°˜í™˜\n",
    "encodings = tokenizer(\n",
    "    train_texts, \n",
    "    truncation=True,\n",
    "    padding=\"max_length\",\n",
    "    max_length=MAX_LEN,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# ğŸ”  ì¸ì½”ë”© ê²°ê³¼ì—ì„œ input_idsì™€ attention_mask ì¶”ì¶œ\n",
    "# input_ids: í† í°ì˜ ì •ìˆ˜ ì¸ë±ìŠ¤\n",
    "# attention_mask: íŒ¨ë”©ì´ ì•„ë‹Œ ë¶€ë¶„ì€ 1, íŒ¨ë”©ëœ ë¶€ë¶„ì€ 0\n",
    "train_inputs = encodings[\"input_ids\"]\n",
    "train_masks = encodings[\"attention_mask\"]\n",
    "\n",
    "# ğŸ·ï¸ ë¼ë²¨ë„ torch í…ì„œ í˜•íƒœë¡œ ë³€í™˜ (ëª¨ë¸ í•™ìŠµì— ì‚¬ìš©í•˜ê¸° ìœ„í•¨)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6157617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§³ PyTorch Dataset ë° Dataloader êµ¬ì„±\n",
    "\n",
    "# í•œ ë²ˆì— í•™ìŠµí•  ë°ì´í„° ìˆ˜ ì„¤ì • (ë¯¸ë‹ˆ ë°°ì¹˜ í¬ê¸°)\n",
    "batch_size = 16\n",
    "\n",
    "# ğŸ“¦ TensorDataset: ì…ë ¥ ë°ì´í„°(input_ids), ë§ˆìŠ¤í¬(attention_mask), ì •ë‹µ ë¼ë²¨(labels)ì„ í•˜ë‚˜ì˜ Datasetìœ¼ë¡œ ë¬¶ìŒ\n",
    "# => í•™ìŠµ ì‹œ ê° ì¸ë±ìŠ¤ì— ëŒ€í•´ (input_ids, attention_mask, label)ì„ ë°˜í™˜\n",
    "train_dataset = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "\n",
    "# ğŸšš DataLoader: ì‹¤ì œ í•™ìŠµì—ì„œ ë°°ì¹˜ ë‹¨ìœ„ë¡œ ë°ì´í„°ë¥¼ ê³µê¸‰í•´ì£¼ëŠ” ì—­í• \n",
    "# RandomSampler: ë§¤ epochë§ˆë‹¤ ë°ì´í„°ë¥¼ **ë¬´ì‘ìœ„ë¡œ ì„ì–´** ìƒ˜í”Œë§ â†’ í•™ìŠµ ì„±ëŠ¥ í–¥ìƒì— ë„ì›€\n",
    "# batch_size: í•œ ë°°ì¹˜ì— í¬í•¨ë  ìƒ˜í”Œ ìˆ˜\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset,                     # í•™ìŠµí•  ë°ì´í„°ì…‹\n",
    "    sampler=RandomSampler(train_dataset),  # ëœë¤ ìƒ˜í”Œë§ (epochë§ˆë‹¤ ë°ì´í„° ìˆœì„œ ì„ê¸°)\n",
    "    batch_size=batch_size             # í•œ ë²ˆì— ì½ì–´ì˜¬ ìƒ˜í”Œ ê°œìˆ˜ (ë°°ì¹˜ ë‹¨ìœ„)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "27acfbea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”§ GPU ì‚¬ìš© ì—¬ë¶€ í™•ì¸\n",
    "# CUDAê°€ ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ GPU ì‚¬ìš©, ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ CPU ì‚¬ìš©\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ğŸ§  ì‚¬ì „í•™ìŠµëœ BERT ë¶„ë¥˜ ëª¨ë¸ ë¡œë”©\n",
    "# 'bert-base-uncased': ì†Œë¬¸ìí™”ëœ BERT ì‚¬ì „í•™ìŠµ ëª¨ë¸\n",
    "# num_labels=2: ì´ì§„ ë¶„ë¥˜ ë¬¸ì œ (ê¸ì •/ë¶€ì •)\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "\n",
    "# ëª¨ë¸ì„ ì„ íƒí•œ ì¥ì¹˜(GPU ë˜ëŠ” CPU)ë¡œ ì´ë™\n",
    "model.to(device)\n",
    "\n",
    "# ğŸ” ì˜µí‹°ë§ˆì´ì € ë° í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •\n",
    "# AdamW: BERT ë…¼ë¬¸ì—ì„œ ê¶Œì¥í•˜ëŠ” ì˜µí‹°ë§ˆì´ì € (ê°€ì¤‘ì¹˜ ê°ì‡  ì ìš©)\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, eps=1e-8)\n",
    "\n",
    "# ì´ í•™ìŠµ epoch ìˆ˜ ì„¤ì •\n",
    "epochs = 2\n",
    "\n",
    "# ì „ì²´ í•™ìŠµ ìŠ¤í… ìˆ˜ ê³„ì‚° (ì´ ë°°ì¹˜ ìˆ˜ Ã— epoch ìˆ˜)\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# í•™ìŠµë¥  ìŠ¤ì¼€ì¤„ëŸ¬ ì„¤ì •\n",
    "# Warm-up ì—†ì´ ì„ í˜• ê°ì†Œ ë°©ì‹ìœ¼ë¡œ í•™ìŠµë¥  ì¡°ì •\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,                 # ì‚¬ìš©í•  ì˜µí‹°ë§ˆì´ì €\n",
    "    num_warmup_steps=0,        # warm-up ë‹¨ê³„ ì—†ìŒ\n",
    "    num_training_steps=total_steps  # ì „ì²´ í•™ìŠµ ìŠ¤í… ìˆ˜\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdf96d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "  â–¶ Step 0/125 - Elapsed: 0:00:00\n",
      "  â–¶ Step 100/125 - Elapsed: 0:20:38\n",
      "âœ… Epoch 1 Avg Loss: 0.5036\n",
      "ğŸ•’ Epoch time: 0:25:37\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "  â–¶ Step 0/125 - Elapsed: 0:00:00\n",
      "  â–¶ Step 100/125 - Elapsed: 0:18:21\n",
      "âœ… Epoch 2 Avg Loss: 0.2471\n",
      "ğŸ•’ Epoch time: 0:23:10\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# ğŸ§¬ ëœë¤ ì‹œë“œ ê³ ì • (ê²°ê³¼ ì¬í˜„ ê°€ëŠ¥ì„±ì„ ë†’ì´ê¸° ìœ„í•¨)\n",
    "seed_val = 777\n",
    "random.seed(seed_val)                    # íŒŒì´ì¬ random ê³ ì •\n",
    "np.random.seed(seed_val)                # ë„˜íŒŒì´ random ê³ ì •\n",
    "torch.manual_seed(seed_val)             # PyTorch random ê³ ì •\n",
    "torch.cuda.manual_seed_all(seed_val)    # CUDAì—ì„œë„ ë™ì¼í•˜ê²Œ ì‹œë“œ ê³ ì •\n",
    "\n",
    "# í•™ìŠµ ì‹œê°„ í¬ë§· í•¨ìˆ˜ (ì´ˆ â†’ ì‹œ:ë¶„:ì´ˆ)\n",
    "def format_time(elapsed):\n",
    "    return str(datetime.timedelta(seconds=int(round(elapsed))))\n",
    "\n",
    "# ğŸ‹ï¸ ëª¨ë¸ í•™ìŠµ ì‹œì‘\n",
    "model.train()  # ëª¨ë¸ì„ í•™ìŠµ ëª¨ë“œë¡œ ì „í™˜ (Dropout, BatchNorm ë“±ì´ í•™ìŠµ ëª¨ë“œë¡œ ì‘ë™)\n",
    "\n",
    "# ê° epoch ë°˜ë³µ\n",
    "for epoch_i in range(epochs):\n",
    "    print(f\"\\n======== Epoch {epoch_i + 1} / {epochs} ========\")\n",
    "    t0 = time.time()  # í•™ìŠµ ì‹œì‘ ì‹œê°„ ì €ì¥\n",
    "    total_loss = 0    # ëˆ„ì  ì†ì‹¤ ì´ˆê¸°í™”\n",
    "\n",
    "    # ë¯¸ë‹ˆë°°ì¹˜ ë°˜ë³µ\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        # ë§¤ 100ìŠ¤í…ë§ˆë‹¤ ê²½ê³¼ ì‹œê°„ ì¶œë ¥\n",
    "        if step % 100 == 0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print(f\"  â–¶ Step {step}/{len(train_dataloader)} - Elapsed: {elapsed}\")\n",
    "\n",
    "        # ì…ë ¥ ë°ì´í„°ì™€ ë¼ë²¨ì„ ì¥ì¹˜(GPU/CPU)ë¡œ ì´ë™\n",
    "        b_input_ids, b_input_mask, b_labels = [b.to(device) for b in batch]\n",
    "\n",
    "        model.zero_grad()  # ê¸°ìš¸ê¸° ì´ˆê¸°í™”\n",
    "\n",
    "        # ğŸ” ìˆœì „íŒŒ â†’ ì†ì‹¤ ê³„ì‚°\n",
    "        outputs = model(\n",
    "            b_input_ids, \n",
    "            attention_mask=b_input_mask, \n",
    "            labels=b_labels\n",
    "        )\n",
    "        loss = outputs.loss         # CrossEntropyLoss í¬í•¨\n",
    "        total_loss += loss.item()   # ì†ì‹¤ ëˆ„ì \n",
    "\n",
    "        # ğŸ”„ ì—­ì „íŒŒ â†’ ê°€ì¤‘ì¹˜ ê°±ì‹ \n",
    "        loss.backward()  # ì†ì‹¤ ê¸°ì¤€ìœ¼ë¡œ ì—­ì „íŒŒ ìˆ˜í–‰\n",
    "\n",
    "        # ê·¸ë˜ë””ì–¸íŠ¸ í´ë¦¬í•‘: exploding gradient ë°©ì§€\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()  # ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸\n",
    "        scheduler.step()  # í•™ìŠµë¥  ì¡°ì •\n",
    "\n",
    "    # â± ì—í­ ë‹¨ìœ„ í‰ê·  ì†ì‹¤ ì¶œë ¥\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"âœ… Epoch {epoch_i+1} Avg Loss: {avg_loss:.4f}\")\n",
    "    print(f\"ğŸ•’ Epoch time: {format_time(time.time() - t0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "294043d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "c:\\Users\\kdecs\\anaconda3\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:106: UserWarning: `return_all_scores` is now deprecated,  if want a similar functionality use `top_k=None` instead of `return_all_scores=True` or `top_k=1` instead of `return_all_scores=False`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Œ ì…ë ¥ ë¬¸ì¥: This movie was absolutely fantastic. I loved the plot and the characters.\n",
      "  LABEL_0 â†’ 0.0417\n",
      "  LABEL_1 â†’ 0.9583\n",
      "\n",
      "ğŸ“Œ ì…ë ¥ ë¬¸ì¥: It was the worst film I have ever seen. Completely boring.\n",
      "  LABEL_0 â†’ 0.9469\n",
      "  LABEL_1 â†’ 0.0531\n",
      "\n",
      "ğŸ“Œ ì…ë ¥ ë¬¸ì¥: Not bad, but not great either. Just okay.\n",
      "  LABEL_0 â†’ 0.8529\n",
      "  LABEL_1 â†’ 0.1471\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# ğŸ“ GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸ â†’ GPUê°€ ìˆìœ¼ë©´ 0, ì—†ìœ¼ë©´ CPU(-1)ë¡œ ì„¤ì •\n",
    "device_id = 0 if torch.cuda.is_available() else -1\n",
    "\n",
    "# ğŸ¤– í•™ìŠµëœ ëª¨ë¸ë¡œ íŒŒì´í”„ë¼ì¸ êµ¬ì„±\n",
    "clf_pipeline = pipeline(\n",
    "    task=\"text-classification\",        # ì‘ì—… ìœ í˜•: ë¬¸ì¥ ë¶„ë¥˜\n",
    "    model=model,                       # fine-tuningëœ BERT ë¶„ë¥˜ ëª¨ë¸\n",
    "    tokenizer=tokenizer,               # ê°™ì€ baseì˜ í† í¬ë‚˜ì´ì € ì‚¬ìš©\n",
    "    device=device_id,                  # ë””ë°”ì´ìŠ¤ ì„¤ì •: GPU or CPU\n",
    "    return_all_scores=True,            # ë‘ í´ë˜ìŠ¤ì˜ í™•ë¥  ëª¨ë‘ ì¶œë ¥\n",
    "    function_to_apply=\"softmax\"        # ì¶œë ¥ ë¡œì§“ â†’ í™•ë¥ ê°’ìœ¼ë¡œ ë³€í™˜\n",
    ")\n",
    "\n",
    "# ğŸ” ì˜ˆì¸¡í•  í…ŒìŠ¤íŠ¸ ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸\n",
    "sample_texts = [\n",
    "    \"This movie was absolutely fantastic. I loved the plot and the characters.\",   # ê¸ì •\n",
    "    \"It was the worst film I have ever seen. Completely boring.\",                  # ë¶€ì •\n",
    "    \"Not bad, but not great either. Just okay.\"                                    # ì¤‘ë¦½ì— ê°€ê¹Œì›€ (íŒë‹¨ ì• ë§¤)\n",
    "]\n",
    "\n",
    "# ğŸ§¾ íŒŒì´í”„ë¼ì¸ì„ í†µí•´ ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "predictions = clf_pipeline(sample_texts)\n",
    "\n",
    "# ğŸ“‹ ê° ë¬¸ì¥ë³„ ì˜ˆì¸¡ ê²°ê³¼ ì¶œë ¥\n",
    "for text, result in zip(sample_texts, predictions):\n",
    "    print(f\"\\nğŸ“Œ ì…ë ¥ ë¬¸ì¥: {text}\")\n",
    "    for label in result:\n",
    "        print(f\"  {label['label']} â†’ {label['score']:.4f}\")  # label: POSITIVE/NEGATIVE, score: í™•ë¥ ê°’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e56d91aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Test Accuracy: 0.8920\n",
      "âœ… Test F1 Score: 0.9429\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from torch.utils.data import DataLoader, SequentialSampler\n",
    "\n",
    "# ğŸ¯ í…ŒìŠ¤íŠ¸ì…‹ ì „ì²˜ë¦¬\n",
    "test_texts = test_data[\"text\"]             # í…ŒìŠ¤íŠ¸ ë¬¸ì¥ ë¦¬ìŠ¤íŠ¸\n",
    "test_labels = test_data[\"label\"]           # í…ŒìŠ¤íŠ¸ ë ˆì´ë¸” ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "# ğŸ§ª í† í¬ë‚˜ì´ì§• ë° ì¸ì½”ë”© (í›ˆë ¨ê³¼ ë™ì¼í•˜ê²Œ max_length ê¸°ì¤€ padding/truncation ìˆ˜í–‰)\n",
    "test_encodings = tokenizer(\n",
    "    test_texts,\n",
    "    truncation=True,\n",
    "    padding=\"max_length\",\n",
    "    max_length=MAX_LEN,\n",
    "    return_tensors=\"pt\"                    # PyTorch í…ì„œ í˜•íƒœë¡œ ë°˜í™˜\n",
    ")\n",
    "\n",
    "test_inputs = test_encodings[\"input_ids\"]         # ì…ë ¥ í† í° ID\n",
    "test_masks = test_encodings[\"attention_mask\"]     # ì–´í…ì…˜ ë§ˆìŠ¤í¬\n",
    "test_labels_tensor = torch.tensor(test_labels)    # ì •ë‹µ ë ˆì´ë¸”\n",
    "\n",
    "# ğŸ“¦ PyTorchìš© í…ŒìŠ¤íŠ¸ Dataset ë° DataLoader êµ¬ì„±\n",
    "test_dataset = TensorDataset(test_inputs, test_masks, test_labels_tensor)\n",
    "test_dataloader = DataLoader(test_dataset, sampler=SequentialSampler(test_dataset), batch_size=batch_size)\n",
    "\n",
    "# ğŸ“ˆ í‰ê°€ í•¨ìˆ˜ ì •ì˜\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()              # í‰ê°€ ëª¨ë“œ (Dropout/BatchNorm ë“± ë¹„í™œì„±í™”)\n",
    "    preds = []                # ì˜ˆì¸¡ê°’ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸\n",
    "    true_labels = []          # ì‹¤ì œê°’ ì €ì¥ìš© ë¦¬ìŠ¤íŠ¸\n",
    "\n",
    "    for batch in dataloader:\n",
    "        # ë¯¸ë‹ˆë°°ì¹˜ ë°ì´í„°ë¥¼ GPU/CPUë¡œ ì´ë™\n",
    "        b_input_ids, b_input_mask, b_labels = [b.to(device) for b in batch]\n",
    "        \n",
    "        with torch.no_grad():  # ê·¸ë˜ë””ì–¸íŠ¸ ê³„ì‚° ë¹„í™œì„±í™” (ì†ë„â†‘, ë©”ëª¨ë¦¬â†“)\n",
    "            outputs = model(b_input_ids, attention_mask=b_input_mask)\n",
    "\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=1).cpu().numpy()  # ê°€ì¥ í™•ë¥  ë†’ì€ í´ë˜ìŠ¤ ì„ íƒ\n",
    "        labels = b_labels.cpu().numpy()\n",
    "\n",
    "        preds.extend(predictions)      # ì˜ˆì¸¡ ê²°ê³¼ ëˆ„ì \n",
    "        true_labels.extend(labels)     # ì‹¤ì œ ë ˆì´ë¸” ëˆ„ì \n",
    "\n",
    "    return preds, true_labels\n",
    "\n",
    "# ğŸ§ª í‰ê°€ ì‹¤í–‰\n",
    "preds, true_labels = evaluate_model(model, test_dataloader)\n",
    "\n",
    "# âœ… ì •í™•ë„ ë° F1 ì ìˆ˜ ê³„ì‚° ë° ì¶œë ¥\n",
    "acc = accuracy_score(true_labels, preds)                         # ì •í™•ë„: ì˜ˆì¸¡ê³¼ ì‹¤ì œ ì¼ì¹˜ ë¹„ìœ¨\n",
    "f1 = f1_score(true_labels, preds, average='weighted')            # F1 ì ìˆ˜: ì •ë°€ë„ì™€ ì¬í˜„ìœ¨ì˜ ì¡°í™” í‰ê· \n",
    "\n",
    "print(f\"\\nâœ… Test Accuracy: {acc:.4f}\")\n",
    "print(f\"âœ… Test F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8346966b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Counter\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# ì• 10,000ê°œë§Œ ì„ íƒ\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m train_subset \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m10000\u001b[39m))\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# ë ˆì´ë¸” ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ\u001b[39;00m\n\u001b[0;32m      7\u001b[0m labels \u001b[38;5;241m=\u001b[39m train_subset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset' is not defined"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# ì• 10,000ê°œë§Œ ì„ íƒ\n",
    "train_subset = dataset[\"train\"].select(range(10000))\n",
    "\n",
    "# ë ˆì´ë¸” ë¦¬ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "labels = train_subset[\"label\"]\n",
    "\n",
    "# ë ˆì´ë¸” ë¶„í¬ í™•ì¸\n",
    "label_count = Counter(labels)\n",
    "print(label_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c383ab76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
