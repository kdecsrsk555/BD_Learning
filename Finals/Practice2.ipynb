{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11a6d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜¸ì¶œ ê³µê°„\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46756088",
   "metadata": {},
   "source": [
    "ë°ì´í„° ì „ì²˜ë¦¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553e616c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "file_name = \"\"\n",
    "def reading_csv(filename):\n",
    "    df = pd.read_csv(filename)\n",
    "    print(df.shape)\n",
    "    print(df.head())\n",
    "    return df\n",
    "\n",
    "df = reading_csv(file_name)\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ í™•ì¸\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# ê²°ì¸¡ì¹˜ ì²˜ë¦¬ (í‰ê·  or ìµœë¹ˆê°’ or ì¤‘ìœ„ê°’)\n",
    "si = SimpleImputer(strategy=\"mean\")\n",
    "ss = StandardScaler()\n",
    "le = LabelEncoder()\n",
    "oe = OneHotEncoder(sparse=False)\n",
    "num_col = []\n",
    "cat_col = []\n",
    " \n",
    "def processing(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ì²˜ë¦¬\n",
    "    df[num_col] = si.fit_transform(df[num_col])\n",
    "    df['íŒŒìƒë³€ìˆ˜'] = pd.cut(df['col'], bins=[0, 18, 30, 50, 100], labels=['Teen', 'Young', 'Adults', 'Senior'])\n",
    "    df[num_col] = ss.fit_transform(df[num_col])\n",
    "\n",
    "    # ë²”ì£¼í˜• ì»¬ëŸ¼ ì²˜ë¦¬\n",
    "    for col in cat_col:# label encoding\n",
    "            df[col] = le.fit_transform(df[col])\n",
    "\n",
    "    return df\n",
    "\n",
    "processed_df = processing(df)\n",
    "print(processed_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523ee0ca",
   "metadata": {},
   "source": [
    "Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14852af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# íƒ€ê²Ÿ ë³€ìˆ˜ ì§€ì •\n",
    "target_col = 'target'  # ì‹¤ì œ ë³€ìˆ˜ëª…ìœ¼ë¡œ ë³€ê²½\n",
    "\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "# í›ˆë ¨/ê²€ì¦ ë°ì´í„° ë¶„í•  (8:2)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee432c46",
   "metadata": {},
   "source": [
    "ëª¨ë¸ ì ìš©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01aa9909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ëª¨ë¸ ì ìš© ë° ì„±ëŠ¥ í‰ê°€\n",
    "from sklearn import linear_model  \n",
    "# ë¡œì§€ìŠ¤í‹± íšŒê·€ (ì´ì§„ ë¶„ë¥˜ì— íŠ¹í™”)\n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "# ì•™ìƒë¸” ëª¨ë¸: ì—¬ëŸ¬ ê²°ì •íŠ¸ë¦¬ë¥¼ ê²°í•©í•˜ì—¬ ì„±ëŠ¥ í–¥ìƒ\n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "# ë‹¨ìˆœ ì‹ ê²½ë§ ê¸°ë°˜ì˜ ì„ í˜• ë¶„ë¥˜ê¸°\n",
    "from sklearn.linear_model import Perceptron  \n",
    "# í™•ë¥ ì  ê²½ì‚¬í•˜ê°•ë²• ê¸°ë°˜ ì„ í˜• ë¶„ë¥˜ê¸°\n",
    "from sklearn.linear_model import SGDClassifier  \n",
    "# ê²°ì • íŠ¸ë¦¬ ê¸°ë°˜ ë¶„ë¥˜ê¸° (if-else í˜•íƒœì˜ íŠ¸ë¦¬ êµ¬ì¡°)\n",
    "from sklearn.tree import DecisionTreeClassifier  \n",
    "# K-ìµœê·¼ì ‘ ì´ì›ƒ ì•Œê³ ë¦¬ì¦˜ (ê±°ë¦¬ ê¸°ë°˜ ë¶„ë¥˜)\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "# ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹  (ë³µì¡í•œ ê²½ê³„ ë¶„ë¥˜, ë§ˆì§„ ê¸°ë°˜)\n",
    "# LinearSVC: ì„ í˜• SVM (SVMì˜ ì¼ì¢…, ëŒ€ìš©ëŸ‰ì— ë¹ ë¥´ê³  ì„ í˜• ë¶„ë¦¬ì— ì í•©)\n",
    "from sklearn.svm import SVC, LinearSVC  \n",
    "# í™•ë¥  ê¸°ë°˜ ë¶„ë¥˜ê¸° (ì¡°ê±´ë¶€ ë…ë¦½ ê°€ì •)\n",
    "from sklearn.naive_bayes import GaussianNB  \n",
    "\n",
    "# ğŸ”¹ [3] ì‹œê°í™” ë„êµ¬ ì„í¬íŠ¸\n",
    "import seaborn as sns  \n",
    "%matplotlib inline  \n",
    "from matplotlib import pyplot as plt  \n",
    "from matplotlib import style  # ê·¸ë˜í”„ ìŠ¤íƒ€ì¼ ì§€ì •ìš©\n",
    "\n",
    "# ì˜ì‚¬ê²°ì • ë‚˜ë¬´ --> ë³µìë„ê°€ ë†’ì•„ì§€ë©´ ì¼ë°˜í™” ì„±ëŠ¥ì´ ë–¨ì–´ì§, ê³¼ì í•© ê°€ëŠ¥ì„±\n",
    "decision_tree=DecisionTreeClassifier()\n",
    "decision_tree.fit(X_train, y_train)\n",
    "Y_pred=decision_tree.predict(X_test)\n",
    "train_acc_decision_tree=round(decision_tree.score(X_train, y_train)*100, 2)\n",
    "test_acc_decision_tree=round(decision_tree.score(X_test, y_test)*100, 2)\n",
    "train_acc_decision_tree,test_acc_decision_tree\n",
    "\n",
    "\n",
    "# ëœë¤ í¬ë ˆìŠ¤íŠ¸ --> ê³¼ì í•© ë°©ì§€ì— ê°•í•¨, í•˜ì§€ë§Œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ê¸°ë³¸ê°’ ì‚¬ìš© ë“±ìœ¼ë¡œ ì¼ë°˜í™” ì„±ëŠ¥ì´ í¬ê²Œ í–¥ìƒë˜ì§€ ì•ŠìŒ\n",
    "# max_depth, min_sample_leaf ì œí•œ\n",
    "# n_estimator ì¦ê°€\n",
    "# GridSearchCV ì‚¬ìš© --> ìµœì ì˜ í•˜ì´í¼ íŒŒë¼ë¯¸í„° ì¡°ê±´ íƒìƒ‰\n",
    "random_forest=RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(X_train, y_train)\n",
    "Y_prediction=random_forest.predict(X_test)\n",
    "random_forest.score(X_train, y_train)\n",
    "train_acc_random_forest=round(random_forest.score(X_train, y_train)*100, 2)\n",
    "test_acc_random_forest=round(random_forest.score(X_test, y_test)*100, 2)\n",
    "train_acc_random_forest,test_acc_random_forest\n",
    "\n",
    "\n",
    "# ë¡œì§€ìŠ¤í‹± íšŒê·€ --> ê³¼ì í•© ìœ„í—˜ ë‚®ìŒ, íŠ¹íˆ íŠ¹ì„±ì´ ë³„ë¡œ ì—†ì„ ë•Œ\n",
    "log_reg=LogisticRegression()\n",
    "log_reg.fit(X_train, y_train)\n",
    "Y_pred=log_reg.predict(X_test)\n",
    "train_acc_log=round(log_reg.score(X_train, y_train)*100, 2)\n",
    "test_acc_log=round(log_reg.score(X_test, y_test)*100, 2)\n",
    "train_acc_log, test_acc_log\n",
    "\n",
    "\n",
    "# ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ --> ë¡œì§€ìŠ¤í‹± íšŒê·€ë³´ë‹¤ ì„±ëŠ¥ ë‚®ìŒ\n",
    "gaussian=GaussianNB()\n",
    "gaussian.fit(X_train, y_train)\n",
    "Y_pred=gaussian.predict(X_test)\n",
    "train_acc_gaussian=round(gaussian.score(X_train, y_train)*100, 2)\n",
    "test_acc_gaussian=round(gaussian.score(X_test, y_test)*100, 2)\n",
    "train_acc_gaussian,test_acc_gaussian\n",
    "\n",
    "# Linear SVC\n",
    "svc=LinearSVC()\n",
    "svc.fit(X_train, y_train)\n",
    "Y_pred=svc.predict(X_test)\n",
    "train_acc_svc=round(svc.score(X_train, y_train)*100, 2)\n",
    "test_acc_svc=round(svc.score(X_test, y_test)*100, 2)\n",
    "train_acc_svc,test_acc_svc\n",
    "\n",
    "# Perceptron\n",
    "perceptron=Perceptron(max_iter=5)\n",
    "perceptron.fit(X_train, y_train)\n",
    "Y_pred=perceptron.predict(X_test)\n",
    "train_acc_perceptron=round(perceptron.score(X_train, y_train)*100, 2)\n",
    "test_acc_perceptron=round(perceptron.score(X_test, y_test)*100, 2)\n",
    "train_acc_perceptron,test_acc_perceptron\n",
    "\n",
    "\n",
    "#SDGclassifier --> ê³¼ì†Œì í•© (max_iter ëŠ˜ë ¤ì•¼ë¨)\n",
    "sgd=linear_model.SGDClassifier(max_iter=5, tol=None)\n",
    "sgd.fit(X_train, y_train)\n",
    "Y_pred=sgd.predict(X_test)\n",
    "sgd.score(X_train, y_train)\n",
    "train_acc_sgd=round(sgd.score(X_train, y_train)*100, 2)\n",
    "test_acc_sgd=round(sgd.score(X_test, y_test)*100, 2)\n",
    "train_acc_sgd,test_acc_sgd\n",
    "\n",
    "\n",
    "#ëª¨ë¸ ë¹„êµ ë°©ì‹\n",
    "results = pd.DataFrame({\n",
    " 'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', 'Random Forest','Naive Bayes', 'Perceptron', 'Stochastic Gradient Decent', 'Decision Tree'],\n",
    " 'train_Score': [train_acc_svc, train_acc_knn, train_acc_log,train_acc_random_forest,\n",
    "train_acc_gaussian, train_acc_perceptron, train_acc_sgd, train_acc_decision_tree],\n",
    " 'test_Score': [test_acc_svc, test_acc_knn,test_acc_log, test_acc_random_forest, test_acc_gaussian, test_acc_perceptron, test_acc_sgd, test_acc_decision_tree]})\n",
    "result_df=results.sort_values(by='train_Score', ascending=False)\n",
    "result_df=result_df.set_index('Model')\n",
    "result_df.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0528e25",
   "metadata": {},
   "source": [
    "5. ì •ë¦¬\n",
    "\n",
    "\"ëª¨ë“  ëª¨ë¸ì€ ë„êµ¬ì¼ ë¿, ë¬¸ì œì— ë§ê²Œ ê³¨ë¼ ì¨ì•¼ í•œë‹¤.\"\n",
    "\n",
    "ì§ê´€ì´ í•„ìš”í•œê°€? â†’ ê²°ì •ë‚˜ë¬´\n",
    "\n",
    "ì •í™•ë„ê°€ ì¤‘ìš”í•œê°€? â†’ ëœë¤ í¬ë ˆìŠ¤íŠ¸\n",
    "\n",
    "ì‹¤ì‹œê°„ ë°ì´í„°ì¸ê°€? â†’ SGD\n",
    "\n",
    "ì ì€ ë°ì´í„°ì¸ê°€? â†’ ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ\n",
    "\n",
    "ë³€ìˆ˜ ê°„ ë³µì¡í•œ ê´€ê³„ê°€ ìˆëŠ”ê°€? â†’ SVM or ì•™ìƒë¸”\n",
    "\n",
    "\n",
    "\n",
    "í•­ëª© & ê³ ë ¤ ë‚´ìš©\n",
    "\n",
    "ë°ì´í„° í¬ê¸° --> ì‘ë‹¤ë©´ SVM/ë¡œì§€ìŠ¤í‹±, í¬ë©´ SGD/ëœë¤í¬ë ˆìŠ¤íŠ¸\n",
    "\n",
    "ë³€ìˆ˜ ê°„ ê´€ê³„ --> ë…ë¦½ì„± ë†’ë‹¤ë©´ ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ ì í•©\n",
    "\n",
    "ì •í˜•/ë¹„ì •í˜• ë°ì´í„° --> ì •í˜•ì´ë©´ ëŒ€ë¶€ë¶„ ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥, ë¹„ì •í˜•ì´ë©´ ë”¥ëŸ¬ë‹ ê³„ì—´\n",
    "\n",
    "ì‹¤í–‰ ì‹œê°„ --> ì‹¤ì‹œê°„ ì²˜ë¦¬ í•„ìš”í•˜ë©´ SGDClassifier\n",
    "\n",
    "ê²°ê³¼ í•´ì„ í•„ìš” --> ì˜ì‚¬ê²°ì •ë‚˜ë¬´, ë¡œì§€ìŠ¤í‹± íšŒê·€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0389ff23",
   "metadata": {},
   "source": [
    "ë³€ìˆ˜ ì¤‘ìš”ë„ ë° í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18320f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# ê¸°ì¡´ ëª¨ë¸ í•™ìŠµ\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# ë³€ìˆ˜ ì¤‘ìš”ë„ ì‹œê°í™” ë° ìƒìœ„ 3ê°œ ë³€ìˆ˜ ì¶”ì¶œ\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# ë³€ìˆ˜ ì¤‘ìš”ë„ ìƒìœ„ 3ê°œ\n",
    "top_3_features = [X_train.columns[i] for i in indices[:3]]\n",
    "print(\"Top 3 ì¤‘ìš” ë³€ìˆ˜:\", top_3_features)\n",
    "\n",
    "# ì‹œê°í™”\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.title(\"Feature Importances\")\n",
    "plt.bar(range(X_train.shape[1]), importances[indices], align=\"center\")\n",
    "plt.xticks(range(X_train.shape[1]), X_train.columns[indices], rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bf40df",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 5, 10],\n",
    "    'min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=42),\n",
    "                           param_grid, scoring='f1', cv=3, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Params:\", grid_search.best_params_)\n",
    "\n",
    "# íŠœë‹ëœ ëª¨ë¸ë¡œ ì˜ˆì¸¡\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_before = model.predict(X_test)\n",
    "y_pred_after = best_model.predict(X_test)\n",
    "\n",
    "print(\"Before tuning - Accuracy:\", accuracy_score(y_test, y_pred_before))\n",
    "print(\"Before tuning - F1 Score:\", f1_score(y_test, y_pred_before, average='macro'))\n",
    "\n",
    "print(\"After tuning - Accuracy:\", accuracy_score(y_test, y_pred_after))\n",
    "print(\"After tuning - F1 Score:\", f1_score(y_test, y_pred_after, average='macro'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30e5752",
   "metadata": {},
   "source": [
    "ì˜¤ë²„í”¼íŒ… ì ê²€ ë° í•´ê²°ë°©ì•ˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ae3a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í›ˆë ¨ ë°ì´í„°ì™€ ê²€ì¦ ë°ì´í„° ì„±ëŠ¥ ë¹„êµ\n",
    "train_acc = best_model.score(X_train, y_train)\n",
    "test_acc = best_model.score(X_test, y_test)\n",
    "\n",
    "print(\"Train Accuracy:\", train_acc)\n",
    "print(\"Test Accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d44720",
   "metadata": {},
   "source": [
    "ì„±ëŠ¥ ì°¨ì´ê°€ í´ ê²½ìš° â†’ ê³¼ì í•©(overfitting) ê°€ëŠ¥ì„± ìˆìŒ.\n",
    "\n",
    "ì˜¤ë²„í”¼íŒ… ë°©ì§€ ë°©ë²• ì œì•ˆ\n",
    "êµì°¨ ê²€ì¦ (Cross-validation)\n",
    "\n",
    "ì •ê·œí™” (Regularization)\n",
    "\n",
    "ë³€ìˆ˜ ê°œìˆ˜ ì¶•ì†Œ / ë¶ˆí•„ìš”í•œ ë³€ìˆ˜ ì œê±°\n",
    "\n",
    "ëª¨ë¸ ë³µì¡ë„ ì œí•œ (max_depth, min_samples_split ì¡°ì • ë“±)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf6c8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max depth ì œí•œì„ í†µí•´ ëª¨ë¸ ë³µì¡ë„ ì œí•œ\n",
    "simple_model = RandomForestClassifier(max_depth=5, random_state=42)\n",
    "simple_model.fit(X_train, y_train)\n",
    "y_simple_pred = simple_model.predict(X_test)\n",
    "\n",
    "print(\"After applying max_depth=5 - Accuracy:\", accuracy_score(y_test, y_simple_pred))\n",
    "print(\"After applying max_depth=5 - F1 Score:\", f1_score(y_test, y_simple_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e088b499",
   "metadata": {},
   "source": [
    "ì¢…í•© í•´ì„ ë° ì œì•ˆ\n",
    "\n",
    "### ëª¨ë¸ í™œìš© ë°©ì•ˆ\n",
    "í•´ë‹¹ ë¶„ë¥˜ ëª¨ë¸ì€ ì˜ˆì¸¡ ì •í™•ë„ê°€ ë†’ê³  ë³€ìˆ˜ ì¤‘ìš”ë„ë¥¼ í•´ì„í•  ìˆ˜ ìˆì–´, ì˜ˆì¸¡ì´ í•„ìš”í•œ ì‹¤ì œ ì—…ë¬´ì— ì ìš© ê°€ëŠ¥í•˜ë‹¤. ì˜ˆ: ê³ ê° ì´íƒˆ ì˜ˆì¸¡, ì§ˆë³‘ ë¶„ë¥˜, ì´ìƒ ê±°ë˜ íƒì§€ ë“±\n",
    "\n",
    "### ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•œ ë°ì´í„° ì¸¡ë©´ ì œì•ˆ\n",
    "1. **ë” ë§ì€ í•™ìŠµ ë°ì´í„° í™•ë³´**: í˜„ì¬ ë°ì´í„°ê°€ ì œí•œì ì¼ ê²½ìš°, ì¶”ê°€ ìˆ˜ì§‘ì„ í†µí•´ ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ ê°€ëŠ¥\n",
    "2. **ë„ë©”ì¸ íŠ¹í™”ëœ íŒŒìƒë³€ìˆ˜ ìƒì„±**: ë‹¨ìˆœ ë³€ìˆ˜ ì™¸ì—ë„ ì—…ë¬´ ì§€ì‹ì— ê¸°ë°˜í•œ íŒŒìƒ ë³€ìˆ˜ ì¶”ê°€ ì‹œ ì„±ëŠ¥ í–¥ìƒ ê°€ëŠ¥\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
